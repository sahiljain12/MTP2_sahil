{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UNmY5R5DGV3-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import random\n",
    "import math\n",
    "import io\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "from IPython.display import HTML\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"CPU\")\n",
    "# device='cpu'\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import time\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "import numpy as np\n",
    "from matplotlib.colors import Normalize\n",
    "import random\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "import cv2\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is used to create few samples from training and saved them to apply data augmentation technique to them and create synthetic data\n",
    "\n",
    "# path='/home/scai/mtech/aib222677/scratch/Task2/data'\n",
    "# data_path_Train = os.path.join(path,'train')\n",
    "# img_path=[os.path.join(data_path_Train, filename) for filename in os.listdir(data_path_Train)]\n",
    "# original_dataset=[]\n",
    "# for i,data in enumerate(img_path):\n",
    "#     image = Image.open(data)\n",
    "#     to_tensor = transforms.ToTensor()\n",
    "#     image=to_tensor(image)\n",
    "#     if i%5==0:\n",
    "#         original_dataset.append(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "augmentation_transform_gaussian = transforms.Compose([\n",
    "   \n",
    "    transforms.GaussianBlur(kernel_size=29, sigma=11),\n",
    "    \n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "augmentation_transform_gamma= transforms.Compose([transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path='/home/scai/mtech/aib222677/scratch/Task2/data'\n",
    "path_test='/home/scai/mtech/aib222677/scratch/Task4/data'\n",
    "path1='/home/scai/mtech/aib222677/scratch/Task4/C/test'\n",
    "data_path_Train = os.path.join(path,'train') #Enter the train folder directory\n",
    "data_path_Test = os.path.join(path_test,'test') #Enter the test folder directory\n",
    "batch_size = 30\n",
    "num_workers = 2 \n",
    "transform_train_x = transforms.Compose([\n",
    "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "     # for data augmentation\n",
    "                                # transforms.GaussianBlur(kernel_size=5),\n",
    "                               # transforms.RandomRotation(degrees=60),\n",
    "                                     ])\n",
    "                               \n",
    "transform_train_y = transforms.Compose([\n",
    "                                \n",
    "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "                       # for data augmentation\n",
    "                                # transforms.GaussianBlur(kernel_size=5),\n",
    "                               # transforms.RandomRotation(degrees=60),\n",
    "                               \n",
    "                                     ])\n",
    "\n",
    "transform= transforms.Compose([transforms.Resize((256,512)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this will create a class for training data containing both mri sequences 9real and target) as a single merge image of shape (256,512)\n",
    "class MRIImage(Dataset):\n",
    "    def __init__(self, data_dir, transform1=None,transform2=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform1 = transform1\n",
    "        self.transform2=transform2\n",
    "        # self.transform3=transform3\n",
    "        self.image_paths = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir)]\n",
    "\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path)\n",
    "        # image=\n",
    "        to_tensor = transforms.ToTensor()\n",
    "        image=to_tensor(image)\n",
    "        # print(image.shape)\n",
    "        img1=image[:,:,:256]\n",
    "        img2=image[:,:,256:]\n",
    "\n",
    "        # if random.random() < 0.1:\n",
    "        if self.transform1:\n",
    "            # if random.random()<0.1:\n",
    "            #     img1=transforms.functional.adjust_gamma(img1,gamma=0.5,gain=1) # gamma data augmentation\n",
    "            # else:\n",
    "            #     img1=img1\n",
    "        # else:\n",
    "            img1= self.transform1(img1)\n",
    "            # if random.random()<0.1:\n",
    "            #     img1=transforms.functional.adjust_gamma(img1,gamma=0.8,gain=1)\n",
    "            # else:\n",
    "            #     img1=img1\n",
    "        # else:\n",
    "        #     img1= self.transform3(img1)\n",
    "            \n",
    "        if self.transform2:\n",
    "            img2=self.transform2(img2)\n",
    "            \n",
    "        image=torch.cat((img1, img2), dim=2)\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will create a class for test data containing both mri sequences and mask of them\n",
    "\n",
    "class MRIImageTestMasked(Dataset):\n",
    "    def __init__(self, data_dir1,transform=None):\n",
    "        self.data_dir1 = data_dir1\n",
    "       \n",
    "        self.transform = transform\n",
    "        # path to input and output merge image\n",
    "\n",
    "        self.image_paths1 = [os.path.join(data_dir1, filename) for filename in sorted(os.listdir(data_dir1)) if os.path.isfile(os.path.join(data_dir1, filename))]\n",
    "       # path to mask image\n",
    "        self.image_paths2=[x.replace('data','C') for x in self.image_paths1]\n",
    "       \n",
    "    def __len__(self):\n",
    "        # Return the length of the dataset based on the number of images in the directories\n",
    "        return min(len(self.image_paths1), len(self.image_paths2))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load images from the respective directories based on the index\n",
    "        image_path1 = self.image_paths1[idx]\n",
    "        image_path2 = self.image_paths2[idx]\n",
    "\n",
    "        image1 = Image.open(image_path1)\n",
    "        image2 = Image.open(image_path2)\n",
    "\n",
    "        # Apply transformations if specified\n",
    "        if self.transform:\n",
    "            image1 = self.transform(image1) # merge image of input and target of size(256,512)\n",
    "            \n",
    "        image2_array = np.array(image2) # mask image\n",
    "\n",
    "        # Return a dictionary containing the two images\n",
    "        return {'image1': image1, 'image2': image2_array}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to create synthetic data using augmentation technique\n",
    "# class AugmentedImage(Dataset):\n",
    "#     def __init__(self, data,transform1=None,transform2=None,transform3=None):\n",
    "#         self.data = data\n",
    "#         self.transform1 =transform1\n",
    "#         self.transform2=transform2\n",
    "#         self.transform3=transform3\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         image= self.data[index]\n",
    "\n",
    "\n",
    "#         random_number = random.randint(1,2)\n",
    "    \n",
    "#         if random_number == 1:                           (rotation)\n",
    "#            augmented_image = self.transform1(image)\n",
    "#            augmented_dataset.append(augmented_image)\n",
    "\n",
    "            \n",
    "        \n",
    "#         elif random_number == 2:          (gamma transform)\n",
    "#            img1=image[:,:,:256]\n",
    "#            img2=image[:,:,256:]\n",
    "#            img1=transforms.functional.adjust_gamma(img1,gamma=0.5,gain=1)\n",
    "#            i1=self.transform3(img1)\n",
    "#            i2=self.transform3(img2)\n",
    "#            img=torch.cat((i1, i2), dim=2)\n",
    "#            # augmented_dataset.append(img)\n",
    "#            image=img\n",
    "            \n",
    "#         else:                     (gaussian blur)\n",
    "#             img1=image[:,:,:256]\n",
    "#             img2=image[:,:,256:]\n",
    "#             augmented_image = self.transform2(img1)\n",
    "#             img=torch.cat((augmented_image, img2), dim=2)\n",
    "#             image=img\n",
    "           \n",
    "\n",
    "\n",
    "#         return image\n",
    "\n",
    "# augmented_data=AugmentedImage(original_dataset,augmentation_transform,augmentation_transform_gaussian,augmentation_transform_gamma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the entire training dataset\n",
    "full_dataset =MRIImage(data_dir=data_path_Train, transform1=transform_train_x,transform2=transform_train_y)\n",
    "# print(len(full_dataset))   #338 patient data for training\n",
    "\n",
    "\n",
    "\n",
    "train_dataset=full_dataset\n",
    "# when adding synthetic data to the training\n",
    "# train_dataset=full_dataset+augmented_data\n",
    "\n",
    "# print(len(train_dataset))\n",
    "# Create a data loader for training\n",
    "load_Train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bv7QmQJVJ-nS"
   },
   "outputs": [],
   "source": [
    "# Load the entire test dataset\n",
    "full_test_dataset = MRIImageTestMasked(data_dir1=data_path_Test,transform=transform)\n",
    "\n",
    "test_dataset=full_test_dataset\n",
    "# print(len(test_dataset))\n",
    "# Create a data loader for testing\n",
    "load_Test = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DEsnqfLuKHEe",
    "outputId": "044ca266-d90b-42a2-8e1b-9d5b914472ec"
   },
   "outputs": [],
   "source": [
    "#function used to split input and target\n",
    "def split(img):\n",
    "    return img[:,:,:,:256], img[:,:,:,256:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_x5GZanHxVG"
   },
   "outputs": [],
   "source": [
    "inst_norm = True if batch_size==1 else False  # instance normalization\n",
    "\n",
    "\n",
    "def conv(in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride,\n",
    "    padding=padding)\n",
    "\n",
    "\n",
    "def conv_n(in_channels, out_channels, kernel_size, stride=1, padding=0, inst_norm=False):\n",
    "    if inst_norm == True:\n",
    "        return nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "        stride=stride, padding=padding), nn.InstanceNorm2d(out_channels,\n",
    "        momentum=0.1, eps=1e-5),)\n",
    "    else:\n",
    "        return nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "        stride=stride, padding=padding), nn.BatchNorm2d(out_channels,\n",
    "        momentum=0.1, eps=1e-5),)\n",
    "\n",
    "def tconv(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0,):\n",
    "    return nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=stride,\n",
    "    padding=padding, output_padding=output_padding)\n",
    "\n",
    "def tconv_n(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, inst_norm=False):\n",
    "    if inst_norm == True:\n",
    "        return nn.Sequential(nn.ConvTranspose2d(in_channels, out_channels, kernel_size,\n",
    "        stride=stride, padding=padding, output_padding=output_padding),\n",
    "        nn.InstanceNorm2d(out_channels, momentum=0.1, eps=1e-5),)\n",
    "    else:\n",
    "        return nn.Sequential(nn.ConvTranspose2d(in_channels, out_channels, kernel_size,\n",
    "        stride=stride, padding=padding, output_padding=output_padding),\n",
    "        nn.BatchNorm2d(out_channels, momentum=0.1, eps=1e-5),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5IdmxqS_Icku"
   },
   "outputs": [],
   "source": [
    "dim_c = 3\n",
    "dim_g = 64\n",
    "\n",
    "# Generator class designed for taking input of shape (256,256,3)\n",
    "class Gen(nn.Module):\n",
    "    def __init__(self, inst_norm=False):\n",
    "        super(Gen,self).__init__()\n",
    "        self.n1 = conv(dim_c, dim_g, 4, 2, 1)\n",
    "        self.n2 = conv_n(dim_g, dim_g*2, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n3 = conv_n(dim_g*2, dim_g*4, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n4 = conv_n(dim_g*4, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n5 = conv_n(dim_g*8, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n6 = conv_n(dim_g*8, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n7 = conv_n(dim_g*8, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.n8 = conv(dim_g*8, dim_g*8, 4, 2, 1)\n",
    "\n",
    "        self.m1 = tconv_n(dim_g*8, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m2 = tconv_n(dim_g*8*2, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m3 = tconv_n(dim_g*8*2, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m4 = tconv_n(dim_g*8*2, dim_g*8, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m5 = tconv_n(dim_g*8*2, dim_g*4, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m6 = tconv_n(dim_g*4*2, dim_g*2, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m7 = tconv_n(dim_g*2*2, dim_g*1, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.m8 = tconv(dim_g*1*2, dim_c, 4, 2, 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self,x):\n",
    "        n1 = self.n1(x)\n",
    "        n2 = self.n2(F.leaky_relu(n1, 0.2))\n",
    "        n3 = self.n3(F.leaky_relu(n2, 0.2))\n",
    "        n4 = self.n4(F.leaky_relu(n3, 0.2))\n",
    "        n5 = self.n5(F.leaky_relu(n4, 0.2))\n",
    "        n6 = self.n6(F.leaky_relu(n5, 0.2))\n",
    "        n7 = self.n7(F.leaky_relu(n6, 0.2))\n",
    "        n8 = self.n8(F.leaky_relu(n7, 0.2))\n",
    "        m1 = torch.cat([F.dropout(self.m1(F.relu(n8)), 0.5, training=True), n7], 1)\n",
    "        m2 = torch.cat([F.dropout(self.m2(F.relu(m1)), 0.5, training=True), n6], 1)\n",
    "        m3 = torch.cat([F.dropout(self.m3(F.relu(m2)), 0.5, training=True), n5], 1)\n",
    "        m4 = torch.cat([self.m4(F.relu(m3)), n4], 1)\n",
    "        m5 = torch.cat([self.m5(F.relu(m4)), n3], 1)\n",
    "        m6 = torch.cat([self.m6(F.relu(m5)), n2], 1)\n",
    "        m7 = torch.cat([self.m7(F.relu(m6)), n1], 1)\n",
    "        m8 = self.m8(F.relu(m7))\n",
    "\n",
    "        return self.tanh(m8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eds_dHD5IfYB"
   },
   "outputs": [],
   "source": [
    "dim_d = 64\n",
    "\n",
    "# Discriminator class designed for taking input of shape (256,256,3)\n",
    "class Disc(nn.Module):\n",
    "    def __init__(self, inst_norm=False):\n",
    "        super(Disc,self).__init__()\n",
    "        self.c1 = conv(dim_c*2, dim_d, 4, 2, 1)\n",
    "        self.c2 = conv_n(dim_d, dim_d*2, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.c3 = conv_n(dim_d*2, dim_d*4, 4, 2, 1, inst_norm=inst_norm)\n",
    "        self.c4 = conv_n(dim_d*4, dim_d*8, 4, 1, 1, inst_norm=inst_norm)\n",
    "        self.c5 = conv(dim_d*8, 1, 4, 1, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        xy=torch.cat([x,y],dim=1)\n",
    "        xy=F.leaky_relu(self.c1(xy), 0.2)\n",
    "        xy=F.leaky_relu(self.c2(xy), 0.2)\n",
    "        xy=F.leaky_relu(self.c3(xy), 0.2)\n",
    "        xy=F.leaky_relu(self.c4(xy), 0.2)\n",
    "        xy=self.c5(xy)\n",
    "\n",
    "        return self.sigmoid(xy)\n",
    "\n",
    "def weights_init(z):\n",
    "    cls_name =z.__class__.__name__\n",
    "    if cls_name.find('Conv')!=-1 or cls_name.find('Linear')!=-1:\n",
    "        nn.init.normal_(z.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(z.bias.data, 0)\n",
    "    elif cls_name.find('BatchNorm')!=-1:\n",
    "        nn.init.normal_(z.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(z.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1ffYi1eIi7E"
   },
   "outputs": [],
   "source": [
    "BCE = nn.BCELoss() #binary cross-entropy\n",
    "L1 = nn.L1Loss() # L1 loss\n",
    "L2=nn.MSELoss() # L2 loss\n",
    "#instance normalization\n",
    "Gen_model = Gen(inst_norm).to(device)\n",
    "Disc = Disc(inst_norm).to(device)\n",
    "generator = Gen(inst_norm).to(device)\n",
    "#optimizers\n",
    "# Gen_optim = optim.Adam(Gen.parameters(), lr=2e-4, betas=(0.5, 0.999), weight_decay=0.35)\n",
    "Gen_optim = optim.Adam(Gen_model.parameters(), lr=2e-4, betas=(0.5, 0.999))   #lr=1e-4\n",
    "Disc_optim = optim.Adam(Disc.parameters(), lr=2e-4, betas=(0.5, 0.999))   # lr=5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "id": "qLH0qjIsIoJi",
    "outputId": "05351d34-f0c9-4d4c-a1f9-ae205b54d496"
   },
   "outputs": [],
   "source": [
    "# training and displaying the results of training on few training samples\n",
    "\n",
    "\n",
    "iter_per_plot = 10\n",
    "epochs = 10\n",
    "L1_lambda = 100.0\n",
    "\n",
    "\n",
    "for ep in range(epochs):\n",
    "    for i, data in enumerate(load_Train):\n",
    "        start_time = time.time()\n",
    "        size = data.shape[0]\n",
    "        \n",
    "\n",
    "        x,y = split(data.to(device))\n",
    "        ## for t1 generation using t2 \n",
    "        # y, x= split(data.to(device))\n",
    "\n",
    "        \n",
    "\n",
    "        r_masks = torch.ones(size,1,30,30).to(device)\n",
    "        f_masks = torch.zeros(size,1,30,30).to(device)\n",
    "\n",
    "        # disc\n",
    "        Disc.zero_grad()\n",
    "        r_patch=Disc(y,x)\n",
    "       \n",
    "        \n",
    "        \n",
    "        r_disc_loss=L2(r_patch,r_masks)\n",
    "\n",
    "        fake=Gen_model(x)\n",
    "      \n",
    "\n",
    "        #fake_patch\n",
    "        f_patch = Disc(fake.detach(),x)\n",
    "        # print(f_patch.shape,f_masks.shape)\n",
    "        \n",
    "        f_disc_loss=L2(f_patch,f_masks)\n",
    "        Disc_loss = r_disc_loss + f_disc_loss\n",
    "        \n",
    "        Disc_loss.backward()\n",
    "        Disc_optim.step()\n",
    "\n",
    "        # gen\n",
    "        Gen_model.zero_grad()\n",
    "        f_patch = Disc(fake,x)\n",
    "        f_gan_loss=L2(f_patch,r_masks)\n",
    "\n",
    "        L1_loss = L1(fake,y)\n",
    "        Gen_loss = f_gan_loss + L1_lambda*L1_loss\n",
    "        \n",
    "        Gen_loss.backward()\n",
    "\n",
    "        Gen_optim.step()\n",
    "        end_time = time.time()  # End measuring time for each iteration\n",
    "        elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "       \n",
    "\n",
    "        \n",
    "        if (i+1)%iter_per_plot == 0 :\n",
    "\n",
    "            print('Epoch [{}/{}], Step [{}/{}], disc_loss: {:.4f}, gen_loss: {:.4f},Disc(real): {:.2f}, Disc(fake):{:.2f}, gen_loss_gan:{:.4f}, gen_loss_L1:{:.4f}'.format(ep+1, epochs, i+1, len(load_Train), Disc_loss.item(), Gen_loss.item(), r_disc_loss.item(), f_disc_loss.item(), f_gan_loss.item(), L1_loss.item()))\n",
    "\n",
    "    \n",
    "\n",
    "    if (ep+1)%5==0:\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            Gen_model.eval()\n",
    "            for data in load_Train:\n",
    "                # print(data.shape)\n",
    "                x, y = split(data.to(device))\n",
    "\n",
    "                fake = Gen_model(x)\n",
    "                    \n",
    "                for j in range(fake.shape[0]):\n",
    "                    if j%10==0:\n",
    "                        figs=plt.figure(figsize=(10,10))\n",
    "            \n",
    "                        plt.subplot(1,3,1)\n",
    "                        plt.axis(\"off\")\n",
    "                        plt.title(\"input image\")\n",
    "                        plt.imshow(np.transpose(vutils.make_grid(x[j], nrow=1, padding=5,\n",
    "                        normalize=True).cpu(), (1,2,0)))\n",
    "                    \n",
    "                        plt.subplot(1,3,2)\n",
    "                        plt.axis(\"off\")\n",
    "                        plt.title(\"generated image\")\n",
    "                        plt.imshow(np.transpose(vutils.make_grid(fake[j], nrow=1, padding=5,\n",
    "                        normalize=True).cpu(), (1,2,0)))\n",
    "                    \n",
    "                        plt.subplot(1,3,3)\n",
    "                        plt.axis(\"off\")\n",
    "                        plt.title(\"ground truth\")\n",
    "                        plt.imshow(np.transpose(vutils.make_grid(y[j], nrow=1, padding=5,\n",
    "                        normalize=True).cpu(), (1,2,0)))\n",
    "        \n",
    "                break\n",
    "            Gen_model.train()\n",
    "            \n",
    "    if ep+1==epochs:\n",
    "        torch.save(Gen_model.state_dict(), 't1_to_t2_model_patch.pth')  # saving the model after training\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####visualsing the generated image and plotting the error map\n",
    "\n",
    "batch_size = 1  # Set the batch size to 1 to get a single image in each iteration\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "c=0\n",
    "generator.load_state_dict(torch.load('t1_to_t2_model_augmented.pth', map_location=device)) # loading best saved model\n",
    "\n",
    "for i,data in enumerate(test_loader):\n",
    "    if i%10==0:\n",
    "        c+=1\n",
    "        t_batch=data['image1']\n",
    "        t_x, t_y = split(t_batch)\n",
    "\n",
    "        ## for t1 generation using t2 \n",
    "        # t_y, t_x= split(t_batch.to(device))\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            generator.eval()\n",
    "            fk= generator(t_x.to(device))\n",
    "            t_y=t_y.to(device)\n",
    "            figs=plt.figure(figsize=(10,10))\n",
    "\n",
    "            plt.subplot(1,4,1)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"input image\")\n",
    "            \n",
    "            plt.imshow((np.transpose(vutils.make_grid(t_x[0], nrow=1, padding=5,\n",
    "            normalize=True).cpu(), (1,2,0))))\n",
    "            \n",
    "            \n",
    "            plt.subplot(1,4,2)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"generated image\")\n",
    "            plt.imshow((np.transpose(vutils.make_grid(fk[0], nrow=1, padding=5,\n",
    "            normalize=True).cpu(), (1,2,0))))\n",
    "            # plt.colorbar()\n",
    "            \n",
    "            plt.subplot(1,4,3)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"ground truth\")\n",
    "            plt.imshow((np.transpose(vutils.make_grid(t_y[0], nrow=1, padding=5,\n",
    "            normalize=True).cpu(), (1,2,0))))\n",
    "            \n",
    "            plt.subplot(1,4,4)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"error map\")\n",
    "    \n",
    "            fake_img=fake_img.to(device)\n",
    "            data_eg=np.transpose(np.abs((y_img[0]-fake_img[0]).cpu().numpy()),(1,2,0))\n",
    "            normalized_data=Normalize()(data_eg)\n",
    "            normalized_data=np.mean(normalized_data, axis=2, keepdims=True)\n",
    "            # print(normalized_data.shape)\n",
    "            plt.imshow(np.rot90((normalized_data),k=-1),cmap='jet')\n",
    "\n",
    "\n",
    "            if c==20:\n",
    "                break\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##plotting histogram\n",
    "\n",
    "\n",
    "c=0\n",
    "for i,data in enumerate (test_loader):\n",
    "    if i%155==0:\n",
    "        c+=1\n",
    "        t_batch=data['image1']\n",
    "        t_x, t_y = split(t_batch)\n",
    "        ## for t1 generation using t2 \n",
    "        # t_y, t_x= split(t_batch.to(device))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            generator.eval()\n",
    "            fk= generator(t_x.to(device))\n",
    "            t_y=t_y.to(device)\n",
    "        figs=plt.figure(figsize=(12,3))\n",
    "        plt.subplot(1,2,1)\n",
    "        fake_np_rgb=np.transpose((fk[0].cpu().numpy()),(1,2,0))\n",
    "        fake_np_rgb=Normalize()(fake_np_rgb)\n",
    "        fake_np_gray=np.mean(fake_np_rgb, axis=2)\n",
    "\n",
    "# Plot the histogram\n",
    "        plt.hist(fake_np_gray.flatten(), bins=256, range=[0, 1], density=True, color='red', alpha=0.5)\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('Intensity Value')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Histogram of Grayscale Generated Image (Intensity [0, 1])')\n",
    "        # plt.show()\n",
    "        # figs=plt.figure(figsize=(10,10))\n",
    "        plt.subplot(1,2,2)\n",
    "        true_np_rgb=np.transpose((t_y[0].cpu().numpy()),(1,2,0))\n",
    "        true_np_rgb=Normalize()(true_np_rgb)\n",
    "        true_np_gray=np.mean(true_np_rgb, axis=2)\n",
    "# Plot the histogram\n",
    "        plt.hist(true_np_gray.flatten(), bins=256, range=[0, 1], density=True, color='gray', alpha=0.5)\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('Intensity Value')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Histogram of Grayscale True Image (Intensity [0, 1])')\n",
    "        plt.show()\n",
    "\n",
    "        if c==10:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "71qX34-Ia-_5",
    "outputId": "3f96d0c7-562a-49c8-bc03-ce96105432a6"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# calculating mean rmse and mean ssim\n",
    "# # Assuming you have a dataset called 'test_dataset'\n",
    "batch_size = 1  # Set the batch size to 1 to get a single image in each iteration\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "error_list=[]\n",
    "structural_similarity=[]\n",
    "# Now you can iterate over it with random samples\n",
    "for i,data in enumerate (test_loader):\n",
    "    t_batch=data['image1']\n",
    "    t_x, t_y = split(t_batch)\n",
    "    ## for t1 generation using t2 \n",
    "    # t_y, t_x= split(t_batch.to(device))\n",
    "    with torch.no_grad():\n",
    "        generator.eval()\n",
    "        fk_batch = generator(t_x.to(device))\n",
    "    \n",
    "    t_y_numpy=t_y.numpy()\n",
    "    fk_batch_numpy=fk_batch.cpu().detach().numpy()\n",
    "   \n",
    "    error_list.append(np.sqrt(np.sum((t_y_numpy-fk_batch_numpy)**2)))\n",
    "    t_y_numpy=np.transpose(t_y_numpy.squeeze(), (1, 2, 0))\n",
    "    fk_batch_numpy=np.transpose(fk_batch_numpy.squeeze(), (1, 2, 0))\n",
    "    \n",
    "    ssi=ssim(t_y_numpy,fk_batch_numpy,multichannel=True,win_size=3,data_range=2.0)\n",
    "    structural_similarity.append(ssi)\n",
    "    \n",
    "error_list=np.array(error_list)\n",
    "structural_similarity_np=np.array(structural_similarity)\n",
    "\n",
    "print('mean rmse error :',np.mean(error_list))\n",
    "print('max rmse error:',np.max(error_list))\n",
    "print('min rmse error:',np.min(error_list))\n",
    "print('mean ssim :',np.mean(structural_similarity_np))\n",
    "print('min ssim :',np.min(structural_similarity_np))\n",
    "print('max ssim :',np.max(structural_similarity_np))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate cnr given tumor mask\n",
    "def calculate_cnr(image, tumor_mask):\n",
    "      # Calculate signal difference\n",
    "    if np.any(tumor_mask == 1):\n",
    "        tumor_intensity= np.mean(image[tumor_mask == 1])\n",
    "    else:\n",
    "        tumor_intensity = np.nan\n",
    "        \n",
    "    if np.any(tumor_mask == 1):\n",
    "        background_intensity=np.mean(image[tumor_mask == 0])\n",
    "        noise = np.std(image[tumor_mask == 0])\n",
    "    else:\n",
    "        background_intensity = np.nan\n",
    "        noise=np.nan\n",
    "\n",
    "    if np.isnan(tumor_intensity) or np.isnan(background_intensity):\n",
    "        # Set CNR to a specific value or return NaN\n",
    "        cnr = 0 # or cnr = 0\n",
    "    else:\n",
    "        signal_difference = np.abs(tumor_intensity - background_intensity)\n",
    "        # print(signal_difference)\n",
    "        # Estimate noise (standard deviation of background noise)\n",
    "        \n",
    "        # print(noise)\n",
    "        if noise==0 or np.isnan(noise):\n",
    "            cnr=0\n",
    "        else:\n",
    "        # Calculate CNR\n",
    "            cnr = signal_difference / noise\n",
    "    \n",
    "    # Calculate CNR\n",
    "        # cnr = signal_difference / noise\n",
    "    \n",
    "    return cnr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating relative cnr\n",
    "relative_cnr=[]\n",
    "for i,data in enumerate (test_loader):\n",
    "    # if i==10:\n",
    "    # print(i)\n",
    "    t_batch=data['image1']\n",
    "    mask=data['image2'].numpy().squeeze()\n",
    "    # print((mask.shape))\n",
    "    _, binary_mask = cv2.threshold(mask, 127, 1, cv2.THRESH_BINARY)\n",
    "    # print(np.unique(binary_mask))\n",
    "    \n",
    "    t_x, t_y = split(t_batch)\n",
    "    with torch.no_grad():\n",
    "        generator.eval()\n",
    "        fk_batch = generator(t_x.to(device))\n",
    "    t_y_numpy=t_y.numpy()\n",
    "    fk_batch_numpy=fk_batch.cpu().detach().numpy()\n",
    "    t_y_numpy=np.transpose(t_y_numpy.squeeze(), (1, 2, 0))\n",
    "    fk_batch_numpy=np.transpose(fk_batch_numpy.squeeze(), (1, 2, 0))\n",
    "    \n",
    "    cnr_fake=calculate_cnr(fk_batch_numpy, binary_mask)\n",
    "    cnr_real=calculate_cnr(t_y_numpy, binary_mask)\n",
    "\n",
    "    if cnr_fake!=0 and cnr_real!=0:\n",
    "        \n",
    "        relative_cnr.append(np.abs(cnr_fake-cnr_real))\n",
    "    \n",
    "relative_cnr_numpy=np.array(relative_cnr)\n",
    "print(np.mean(relative_cnr_numpy))\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
